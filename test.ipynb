{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/larion/test/')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import concurrent.futures\n",
    "import concurrent\n",
    "import multiprocessing\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.3\n"
     ]
    }
   ],
   "source": [
    "! python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract feature 2\n",
    "def extract_feature(string:str):\n",
    "    features = string.split(',')\n",
    "    index = int(features[0])\n",
    "    return int(features[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just for check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      799.000000\n",
       "mean      9867.720901\n",
       "std        560.638652\n",
       "min       4573.000000\n",
       "25%       9998.000000\n",
       "50%       9999.000000\n",
       "75%       9999.000000\n",
       "max      10000.000000\n",
       "Name: features, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/train.tsv', sep='\\t')\n",
    "data.features.map(extract_feature).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='./data/train.tsv'\n",
    "chunksize=100\n",
    "\n",
    "## map functions \n",
    "def mean_len(chunk):\n",
    "        return chunk.features.map(extract_feature).sum(), len(chunk)\n",
    "    \n",
    "def std_len(chunk, X=0):\n",
    "    return np.power(chunk.features.map(extract_feature) - X, 2).sum(), len(chunk)\n",
    "\n",
    "def chunk_min(chunk):\n",
    "    extr = chunk.features.map(extract_feature)\n",
    "    c_min = extr.min()\n",
    "    idxmin = extr.idxmin()\n",
    "    return c_min, idxmin\n",
    "\n",
    "## reduce functions\n",
    "def chunk_max(chunk):\n",
    "    extr = chunk.features.map(extract_feature)\n",
    "    c_max = extr.max()\n",
    "    idxmax = extr.idxmax()\n",
    "    return c_max, idxmax\n",
    "\n",
    "def min_reducer(step, cache):\n",
    "    c_min = step[0]\n",
    "    idx_min = step[1]\n",
    "    cache[0] = min(c_min, cache[0])\n",
    "    if cache[0] == c_min:\n",
    "        cache[1] = idx_min\n",
    "\n",
    "def max_reducer(step, cache):\n",
    "    c_max = step[0]\n",
    "    idx_max = step[1]\n",
    "    cache[0] = max(c_max, cache[0])\n",
    "    if cache[0] == c_max:\n",
    "        cache[1] = idx_max\n",
    "    \n",
    "def stat_reducer(step, cache):\n",
    "    chunk_sum, chunk_n = step\n",
    "    cache[0] += chunk_sum\n",
    "    cache[1] += chunk_n    \n",
    "    \n",
    "## multiproceossor map_reduce general pipeline for large files\n",
    "def map_reduce(file, chunksize, map_f, reduce_f, init):\n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=cpu_count - 2) as executor:\n",
    "        futures = [executor.submit(map_f, chunk) for chunk in pd.read_csv(file, chunksize=chunksize, sep='\\t')]\n",
    "        first = True\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            step = future.result()\n",
    "            if first:\n",
    "                cache = init\n",
    "                first = False\n",
    "            reduce_f(step, cache)\n",
    "    return cache   \n",
    "\n",
    "## samples \n",
    "def mean(file='./data/train.tsv', chunksize=100):\n",
    "    Sum, N = map_reduce(file, chunksize, mean_len, stat_reducer, [0, 0])\n",
    "    return Sum/N\n",
    "\n",
    "def std(X, file='./data/train.tsv', chunksize=100):\n",
    "    Sum, N = map_reduce(file, chunksize, partial(std_len, X=X), stat_reducer, [0, 0])\n",
    "    return np.sqrt(Sum / (N-1))\n",
    "\n",
    "def minimum(file='./data/train.tsv', chunksize=100):\n",
    "    res = map_reduce(file, chunksize, chunk_min, min_reducer, [20000, 0])\n",
    "    return res\n",
    "\n",
    "def miximum(file='./data/train.tsv', chunksize=100):\n",
    "    res = map_reduce(file, chunksize, chunk_max, max_reducer, [-1, 0])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare results with check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9867.720901126408, 560.6386516245803, (4573, 640), (10000, 700))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## results\n",
    "X = mean()\n",
    "S = std(X)\n",
    "m, m_indx = minimum()\n",
    "M, M_indx = miximum()\n",
    "X, S, (m, m_indx), (M, M_indx)\n",
    "## Our result match check, nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(inputs, outs, decrease_factor, scale_facltor, chunksize=100):\n",
    "\n",
    "    def norm(decrease_factor, scale_facltor):\n",
    "        def _norm(x):\n",
    "            return (x - decrease_factor) / scale_facltor\n",
    "        return _norm\n",
    "\n",
    "    for chunk in pd.read_csv(inputs, chunksize=chunksize, sep='\\t'):\n",
    "        indx = chunk.features.iloc[0].split(',')[0]\n",
    "        column = f'feature_{indx}_stand'\n",
    "        chunk[column] = chunk.features.map(extract_feature).map(norm(X, S))\n",
    "        columns = ['id_job', column]\n",
    "        chunk[columns].to_csv(outs, mode='a', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you want to use min-max normalization you could pass other factors to this method\n",
    "normalize('./data/test.tsv', './data/test_proc.tsv', X, S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_feature_2_index: 52\n",
      "max_feature_2_abs_mean_diff: 132.27909887359237\n"
     ]
    }
   ],
   "source": [
    "## It is not clear for which file I should estemate max_feature_2_index and max_feature_2_abs_mean_diff. \n",
    "\n",
    "## For test.tsv\n",
    "M, M_indx = miximum(file='./data/test.tsv')\n",
    "print ('max_feature_2_index:', M_indx)\n",
    "print ('max_feature_2_abs_mean_diff:', np.abs(M - X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_feature_2_index: 700\n",
      "max_feature_2_abs_mean_diff: 132.27909887359237\n"
     ]
    }
   ],
   "source": [
    "## For train.tsv\n",
    "M, M_indx = miximum(file='./data/train.tsv')\n",
    "print ('max_feature_2_index:', M_indx)\n",
    "print ('max_feature_2_abs_mean_diff:', np.abs(M - X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-venv",
   "language": "python",
   "name": "test-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
